import os
import glob
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Embeddings / Topic modeling
from sentence_transformers import SentenceTransformer
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer
import umap
import hdbscan

# üëá NYTT: Plotly f√∂r interaktiva figurer
import plotly.express as px

# Stoppord (svenska) inkl. kommuner/landskap + genitiv-s
import nltk, re, unicodedata
from nltk.corpus import stopwords
nltk.download("stopwords", quiet=True)
SWEDISH_STOPWORDS = set(stopwords.words("swedish"))

# (valfritt) l√§gg in kommuner/landskap + "s" fr√•n din tidigare lista om du vill
# H√§r visar jag bara hur du kan hooka in egna stoppord:
EXTRA_STOPWORDS = { "ska", "kommer", "kommun", "kommuner"
    # exempel: "v√§rmland","v√§rmlands","stockholm","stockholms", ...
}
SWEDISH_STOPWORDS.update(EXTRA_STOPWORDS)

# --- Svenska kommuner (SCB-lista, 2024) ---
SWEDISH_MUNICIPALITIES = {
    "alings√•s","alvesta","aneby","arboga","arjeplog","arvidsjaur","arvika","askersund",
    "avesta","bengtsfors","berg","bjurholm","bjuv","boden","bollebygd","bolln√§s","borgholm",
    "borl√§nge","bor√•s","botkyrka","boxholm","brom√∂lla","br√§cke","burl√∂v","b√•stad","dals-ed",
    "danderyd","degervors","dorotea","eda","eksj√∂","emaboda","enk√∂ping","eskilstuna","esl√∂v",
    "essunga","fagersta","falkenberg","falk√∂ping","falun","filipstad","finsp√•ng","flen",
    "forshaga","f√§rgelanda","gagnef","gislaved","gnesta","gnosj√∂","gotland","grums",
    "gr√§storp","gullsp√•ng","g√§llivare","g√§vle","g√∂teborg","g√∂tene","hagfors","hallsberg",
    "hallstahammar","hammar√∂","haninge","haparanda","heby","hedemora","helsingborg",
    "herrljunga","hjo","hofors","huddinge","hudiksvall","hultsfred","hylte","h√•bo",
    "h√§llefors","h√§rjedalen","h√§rn√∂sand","h√§rryda","h√§ssleholm","h√∂gan√§s","h√∂gsby","h√∂rby",
    "h√∂√∂r","jokkmokk","j√∂nk√∂ping","kalix","kalmar","karlsborg","karlshamn","karlskoga",
    "karlskrona","karlstad","katrineholm","kil","kinda","kiruna","klippan","knivsta","kramfors",
    "krokom","kumla","kungsbacka","kungs√∂r","kung√§lv","k√§vlinge","k√∂ping","laholm","landskrona",
    "lax√•","lekeberg","leksand","lerum","liding√∂","lidk√∂ping","lilla edet","lindesberg",
    "link√∂ping","ljungby","ljusdal","ljusnarsberg","lomma","ludvika","lule√•","lund",
    "lycksele","lysekil","malm√∂","malung-s√§len","mariestad","mark","markaryd","mellerud",
    "mj√∂lby","mora","motala","mullsj√∂","munkedal","munkfors","m√∂lndal","m√∂nster√•s","m√∂rbyl√•nga",
    "nacka","nora","norberg","nordanstig","nordmaling","norrk√∂ping","norrt√§lje","nybro","nykvarn",
    "nyk√∂ping","nyn√§shamn","ockelbo","osby","oskarshamn","oxel√∂sund","pajala","partille",
    "perstorp","pite√•","ragunda","robertsfors","ronneby","r√§ttvik","sala","salem","sandviken",
    "sigtuna","simrishamn","sj√∂bo","skara","skellefte√•","skinnskatteberg","skurup","sk√∂vde",
    "smedjebacken","sollefte√•","solna","sorsele","soten√§s","staffanstorp","stenungsund",
    "stockholm","storfors","storuman","str√§ngn√§s","str√∂mstad","sundbyberg","sundsvall",
    "sunne","surahammar","sval√∂v","svedala","svenljunga","s√§ffle","s√§vsj√∂","s√∂derhamn",
    "s√∂derk√∂ping","s√∂dert√§lje","s√∂lvesborg","tanum","tibro","tidaholm","tierp","timr√•",
    "tingsryd","tj√∂rn","tomelilla","torsby","tors√•s","tranemo","tran√•s","trelleborg","trollh√§ttan",
    "trosa","tyres√∂","t√§by","t√∂reboda","uddevalla","ulricehamn","ume√•","upplands v√§sby","upplands-bro",
    "uppsala","vadstena","vaggeryd","valdemarsvik","vallentuna","vansbro","vara","varberg",
    "vaxholm","vellinge","vetlanda","vilhelmina","vimmerby","vindeln","ving√•ker","v√•rg√•rda",
    "v√§nersborg","v√§rmd√∂","v√§rnamo","v√§stervik","v√§ster√•s","v√§xj√∂","ydre","ystad","√•m√•l","√•nge",
    "√•re","√•rj√§ng","√•sele","√•storp","√•tvidaberg","√∂cker√∂","√∂desh√∂g","√∂rebro","√∂rnsk√∂ldsvik",
    "√∂rkelljunga","√∂stersund","√∂sthammar","√∂stra g√∂inge"
}

# --- Svenska landskap ---
SWEDISH_PROVINCES = {
    "blekinge","bohusl√§n","dalarna","dalsland","gotland","g√§strikland","halland","h√§lsingland",
    "h√§rjedalen","j√§mtland","lappland","medelpad","norrbotten","n√§rke","sk√•ne","sm√•land",
    "s√∂dermanland","uppland","v√§rmland","v√§sterbotten","v√§sterg√∂tland","√•ngermanland","√∂land","√∂sterg√∂tland"
}

# --- L√§gg till kommuner, deras genitivformer och landskap till stopporden ---
COMMUNE_STOPWORDS = set()
for name in SWEDISH_MUNICIPALITIES:
    COMMUNE_STOPWORDS.add(name)
    COMMUNE_STOPWORDS.add(name + "s")  # genitivform

PROVINCE_STOPWORDS = set()
for name in SWEDISH_PROVINCES:
    PROVINCE_STOPWORDS.add(name)
    PROVINCE_STOPWORDS.add(name + "s")  # genitivform

SWEDISH_STOPWORDS.update(COMMUNE_STOPWORDS)
SWEDISH_STOPWORDS.update(PROVINCE_STOPWORDS)

# --- S√∂kv√§rdar ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BEFORE_GLOB = os.path.join(BASE_DIR, "data", "F√∂re Markdown", "*.md")
AFTER_GLOB  = os.path.join(BASE_DIR, "data", "Efter Markdown", "*.md")

def normalize_text(s: str) -> str:
    # Unicode-normalisera och rensa dolda tecken
    return unicodedata.normalize("NFKC", s)

def load_markdown_texts(path_pattern, period_label):
    texts, files, labels = [], [], []
    for filepath in sorted(glob.glob(path_pattern)):
        text = Path(filepath).read_text(encoding="utf-8")
        text = normalize_text(text).strip()
        # hoppa √∂ver v√§ldigt korta filer
        if len(text) < 20:
            continue
        texts.append(text)
        files.append(Path(filepath).name)
        labels.append(period_label)
    return texts, files, labels

texts_before, files_before, labels_before = load_markdown_texts(BEFORE_GLOB, "f√∂re")
texts_after,  files_after,  labels_after  = load_markdown_texts(AFTER_GLOB, "efter")

texts = texts_before + texts_after
files = files_before + files_after
periods = labels_before + labels_after

print(f"Totalt {len(texts)} dokument l√§sta ({len(texts_before)} f√∂re, {len(texts_after)} efter).")

# --- Svenska BERT-embeddings fr√•n KB-Lab ---
embed_model_name = "KBLab/sentence-bert-swedish-cased"
embedder = SentenceTransformer(embed_model_name)

print("Ber√§knar embeddings ...")
embeddings = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)

# --- Bygg BERTopic med svensk tokenisering/stoppord ---
# CountVectorizer anv√§nds internt i BERTopic f√∂r c-TF-IDF-tematermer
vectorizer = CountVectorizer(
    stop_words=list(SWEDISH_STOPWORDS),
    lowercase=True,
    token_pattern=r"\b[a-zA-Z√•√§√∂√Ö√Ñ√ñ]{2,}\b",
    ngram_range=(1, 3)  # till√•t bi-/trigram f√∂r b√§ttre temaetiketter
)

# UMAP + HDBSCAN inst√§llningar (kan finjusteras)
umap_model = umap.UMAP(
    n_neighbors=15,
    n_components=5,   # projicera till 5D f√∂r klustring (sen g√∂r vi separat 2D f√∂r plot)
    min_dist=0.0,
    metric="cosine",
    random_state=42
)
hdbscan_model = hdbscan.HDBSCAN(
    min_cluster_size=3,
    min_samples=1,
    metric="euclidean",
    cluster_selection_method="eom",
    prediction_data=True
)

topic_model = BERTopic(
    embedding_model=embedder,     # ger konsekventa embeddings internt
    umap_model=umap_model,
    hdbscan_model=hdbscan_model,
    vectorizer_model=vectorizer,
    language="multilingual",      # explicit spr√•khantering av tokenisering √§r via vectorizer ovan
    top_n_words=10,               # hur m√•nga toppord som ska beskriva ett tema
    calculate_probabilities=True,
    verbose=True
)

# --- Fit-transform (vi skickar ocks√• in f√∂rber√§knade embeddings f√∂r hastighet/stabilitet) ---
topics, probs = topic_model.fit_transform(texts, embeddings=embeddings)

# --- Skapa 2D-koordinater f√∂r visualisering (separat UMAP till 2D f√∂r snygg plot) ---
print("Skapar 2D-embedding f√∂r visualisering ...")
umap_2d = umap.UMAP(
    n_neighbors=15,
    n_components=2,
    min_dist=0.1,
    metric="cosine",
    random_state=42
)
coords_2d = umap_2d.fit_transform(embeddings)

# --- DataFrame med dokument, period, tema, 2D-koordinater ---
df = pd.DataFrame({
    "file": files,
    "period": periods,
    "topic": topics,
    "x": coords_2d[:, 0],
    "y": coords_2d[:, 1],
})

# L√§gg till label per tema (BERTopic genererar etiketter av toppord)
def topic_label(topic_id: int) -> str:
    if topic_id == -1:
        return "T-1: Outlier"
    words = topic_model.get_topic(topic_id)
    if not words:
        return f"T{topic_id}: (tomt)"
    top_terms = ", ".join(w for w, _ in words[:5])
    return f"T{topic_id}: {top_terms}"

df["topic_label"] = df["topic"].apply(topic_label)

# =========================
# üîµ PLOTLy: INTERAKTIVA GRAFIKER
# =========================

# 1) Interaktiv topics-√∂versikt (kluster/teman med toppord)
fig_topics = topic_model.visualize_topics()
fig_topics.write_html(os.path.join(BASE_DIR, "bertopic_topics.html"))

# 2) Interaktiv dokument-plot i 2D (UMAP) med hover som visar dokument och tema
#    (BERTopic r√§knar sj√§lv en 2D-reducering internt om vi inte ger reduced_embeddings)
fig_docs = topic_model.visualize_documents(
    texts,
    embeddings=embeddings,      # anv√§nd dina embeddings f√∂r konsekvent projicering
    custom_labels=True          # anv√§nd interna namn/toppord i hover
)
fig_docs.write_html(os.path.join(BASE_DIR, "bertopic_documents.html"))

# 3) Extra: egen Plotly-scatter (UMAP 2D vi redan ber√§knat) f√§rgad per period + hover
fig_period = px.scatter(
    df, x="x", y="y",
    color="period",
    hover_data={"file": True, "topic": True, "topic_label": True, "x": False, "y": False},
    title="UMAP 2D ‚Äì f√§rgad per period (hover visar fil & tema)"
)
fig_period.write_html(os.path.join(BASE_DIR, "umap_period_scatter.html"))

print("\nüñºÔ∏è Plotly-figurer sparade som:")
print(" - bertopic_topics.html")
print(" - bertopic_documents.html")
print(" - umap_period_scatter.html")

# --- (valfritt) Matplotlib-plot finns kvar om du vill ha statisk bild ---
plt.figure(figsize=(10, 8))
for (period), g in df.groupby("period"):
    plt.scatter(g["x"], g["y"], alpha=0.75, s=50, label=period)
plt.title("Tematiska kluster med BERTopic (UMAP 2D)")
plt.xlabel("UMAP-1")
plt.ylabel("UMAP-2")
plt.legend(title="Period")
plt.tight_layout()
plt.show()

# --- √ñversikt √∂ver teman ---
topic_info = topic_model.get_topic_info()  # kolumner: Topic, Count, Name

def build_name(row):
    tid = int(row["Topic"])
    if tid == -1:
        return "T-1: Outlier"
    words = topic_model.get_topic(tid)
    top_terms = ", ".join(w for w, _ in (words[:5] or []))
    return f"T{tid}: {top_terms}" if top_terms else f"T{tid}"

topic_info["Name"] = topic_info.apply(build_name, axis=1)

# --- Temaf√∂rdelning f√∂re/efter ---
dist = (
    df.groupby(["topic_label", "period"])
      .size()
      .reset_index(name="count")
      .pivot(index="topic_label", columns="period", values="count")
      .fillna(0)
      .astype(int)
)

# S√§kerst√§ll kolumnerna √§ven om en period saknas i datat
for col in ["f√∂re", "efter"]:
    if col not in dist.columns:
        dist[col] = 0

# Sortera efter total antal dokument per tema (flest √∂verst)
dist["_total"] = dist.sum(axis=1)
dist = dist.sort_values("_total", ascending=False).drop(columns="_total")

# --- Exportera till Excel med flera flikar ---
out_path = os.path.join(BASE_DIR, "bertopic_results.xlsx")
with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
    topic_info.to_excel(writer, sheet_name="topics_overview", index=False)
    df[["file", "period", "topic", "topic_label"]].to_excel(writer, sheet_name="doc_topics", index=False)
    dist.to_excel(writer, sheet_name="topic_period_distribution")

print(f"\nüíæ Resultat sparade till: {out_path}")
print("Flikar: topics_overview, doc_topics, topic_period_distribution")

# --- (valfritt) Skriv ut toppord per tema i konsolen ---
print("\n‚Äî Teman och toppord ‚Äî")
for tid in sorted(df["topic"].unique()):
    print(topic_label(tid))
